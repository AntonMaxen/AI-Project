{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"create_storage_hdf5_from_wikiart_sample_test.ipynb","provenance":[],"authorship_tag":"ABX9TyNki04XKjjcdkLVE2s70nfO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kXDWfkW-7pUT","executionInfo":{"status":"ok","timestamp":1618681558530,"user_tz":-120,"elapsed":25552,"user":{"displayName":"ai ai","photoUrl":"","userId":"15194258614812725361"}},"outputId":"6988a854-4d56-4951-fac7-526b88d73ace"},"source":["from google.colab import drive\n","\n","drive.mount(\"/content/gdrive\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"osOoutJx8H6a"},"source":["import h5py\n","import cv2\n","import numpy as np\n","import os\n","from pathlib import Path\n","from tensorflow.keras.preprocessing.image import img_to_array"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SECUNyLu8MGn"},"source":["root = '/content/wikiart'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZbeZFfSd-b6Q"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tIFpx-LH8SJB"},"source":["images = []\n","labels = []\n","\n","import time\n","import datetime\n","\n","start = time.time()\n","f = open(\"names.txt\", \"r\")\n","\n","for folder in os.listdir(root):\n","  for name in os.listdir(os.join(root, folder))\n","    image_path = os.path.join(root, name)\n","    image = cv2.imread(image_path)\n","    image = cv2.resize(image, (128, 128))\n","    f = open(\"demofile3.txt\", \"w\")\n","    break\n","    image = img_to_array(image)\n","    images.append(image)\n","    if 'impressionism' in name:\n","      labels.append(0)\n","    else:\n","      labels.append(1)\n","    break\n","\n","  print(f\"It took : {datetime.timedelta(seconds=int(end - start))}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B8YEjp_W_XY7"},"source":["  import pandas as pd\n","  \n","  art = pd.DataFrame({'title': titles, 'text': corpus})\n","  poems.to_csv(f'{filename}.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3ygmdmngWrUt"},"source":["\n","with h5py.File('train_2.hdf5', 'r') as file:\n","    # Open the HDF5 file\n","    images_new = np.array(file[\"/images\"]).astype(\"uint8\")\n","    labels_new = np.array(file[\"/meta\"]).astype(\"uint8\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mxA_TEw6eDID"},"source":[""]}]}